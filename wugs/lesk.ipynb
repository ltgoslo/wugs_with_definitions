{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8f5e100-61c4-410d-94bc-66db6fe1187a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "import nltk\n",
    "from nltk.wsd import lesk\n",
    "from nltk.corpus import wordnet as wn\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad4a9dcb-b75d-4b40-b065-787fb9972a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/m/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd85d788-d792-4187-aca2-12cada0a9432",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLUSTER_NUMBER_COLUMN = 'cluster'\n",
    "LESK_DIR = os.path.expanduser(f\"~/PycharmProjects/gloss-annotator/predictions/lesk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "80c4c9b7-c5f8-4c5b-8076-cfafe483cdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(LESK_DIR):\n",
    "    os.mkdir(LESK_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7205b9aa-ffb7-4774-960a-ac176165a5f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contemplation_nn\n",
      "ounce_nn\n",
      "fiction_nn\n",
      "bag_nn\n",
      "afternoon_nn\n",
      "quilt_nn\n",
      "player_nn\n",
      "prop_nn\n",
      "ball_nn\n",
      "head_nn\n",
      "lass_nn\n",
      "stroke_vb\n",
      "relationship_nn\n",
      "grain_nn\n",
      "lane_nn\n",
      "stab_nn\n",
      "tree_nn\n",
      "rally_nn\n",
      "graft_nn\n",
      "face_nn\n",
      "record_nn\n",
      "bit_nn\n",
      "land_nn\n",
      "risk_nn\n",
      "heel_nn\n",
      "chairman_nn\n",
      "edge_nn\n",
      "circle_vb\n",
      "thump_nn\n",
      "plane_nn\n",
      "attack_nn\n",
      "tip_vb\n",
      "word_nn\n",
      "bar_nn\n",
      "savage_nn\n",
      "pin_vb\n",
      "rag_nn\n",
      "pick_vb\n",
      "donkey_nn\n",
      "gas_nn\n",
      "include_vb\n",
      "maxim_nn\n",
      "multitude_nn\n",
      "part_nn\n",
      "chef_nn\n",
      "twist_nn\n"
     ]
    }
   ],
   "source": [
    "def lesk_function(lang):\n",
    "    dwug_path = os.path.expanduser(f\"~/PycharmProjects/gloss-annotator/wugs/dwug_{lang}/\")\n",
    "    dwug_predictions_path = os.path.join(LESK_DIR, f\"dwug_{lang}\")\n",
    "    if not os.path.exists(dwug_predictions_path):\n",
    "        os.mkdir(dwug_predictions_path)\n",
    "    for word_path in glob(f\"{dwug_path}data/*\"):\n",
    "        word = os.path.split(word_path)[-1]\n",
    "    \n",
    "        word_uses = pd.read_csv(os.path.join(dwug_path, \"data\", word, \"uses.csv\"), sep=\"\\t\", quoting=csv.QUOTE_NONE)\n",
    "    \n",
    "        clusters_dir = os.path.join(dwug_path, \"clusters/opt\")\n",
    "        if not os.path.exists(clusters_dir):  # no opt in RuDSI data\n",
    "            clusters_dir = os.path.join(dwug_path, \"clusters\")\n",
    "        word_clusters = pd.read_csv(os.path.join(clusters_dir, f\"{word}.csv\"), sep=\"\\t\", quoting=csv.QUOTE_NONE)\n",
    "        word_clusters[CLUSTER_NUMBER_COLUMN] = word_clusters[CLUSTER_NUMBER_COLUMN].astype(int)\n",
    "        this_word = word_uses.join(word_clusters.set_index(\"identifier\"), on=\"identifier\")\n",
    "        word_without_pos, pos = word.split(\"_\")\n",
    "        print(word)\n",
    "        synsets_dict = {synset: synset.definition() for synset in wn.synsets(word_without_pos)}\n",
    "        word_predictions_path = os.path.join(dwug_predictions_path, word)\n",
    "        if not os.path.exists(word_predictions_path):\n",
    "            os.mkdir(word_predictions_path)\n",
    "\n",
    "        cluster_numbers = this_word[CLUSTER_NUMBER_COLUMN].unique()\n",
    "        glosses = []\n",
    "        for cluster_number in cluster_numbers:\n",
    "            this_cluster = this_word[this_word[CLUSTER_NUMBER_COLUMN] == cluster_number]\n",
    "            cluster_uses = \" \".join(this_cluster.context_tokenized).split()\n",
    "            \n",
    "            synset = lesk(cluster_uses, word_without_pos, pos[0])\n",
    "            glosses.append(synsets_dict[synset])\n",
    "\n",
    "        pd.DataFrame(\n",
    "            {\"cluster\": cluster_numbers, \"gloss\": glosses},\n",
    "        ).to_csv(os.path.join(word_predictions_path, \"cluster_gloss.tsv\"), sep=\"\\t\", index=False)\n",
    "\n",
    "        \n",
    "\n",
    "lesk_function(\"en\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "glossannotator",
   "language": "python",
   "name": "glossannotator"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
